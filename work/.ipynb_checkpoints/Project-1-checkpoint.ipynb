{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77e3428-fa17-440a-b8f3-41470c70fda0",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "### Group J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be46f09-5c4a-40a3-a400-9a75737c80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "spark_ok = True\n",
    "try:\n",
    "    import pyspark.sql.functions as F\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.context import SparkContext\n",
    "except Exception as e:\n",
    "    spark_ok = False\n",
    "    print(\"PySpark not available:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3e7331-a80d-4728-8eb1-505373962d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.0\n"
     ]
    }
   ],
   "source": [
    "# Init Spark\n",
    "\n",
    "sc = SparkContext('local', 'project_1')\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('project_1')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e721dc2d-74ff-4859-853a-d327e23dfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables, methods\n",
    "\n",
    "INBOX_DIR = \"data/inbox\"\n",
    "STATE_DIR = \"state\"\n",
    "MANIFEST_PATH = os.path.join(STATE_DIR, \"manifest.json\")\n",
    "LOOKUP_TABLE = \"taxi_zone_lookup.parquet\"\n",
    "\n",
    "def load_manifest(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"processed_files\": []}\n",
    "\n",
    "def list_parquet_files(inbox_dir):\n",
    "    if not os.path.isdir(inbox_dir):\n",
    "        return []\n",
    "    return sorted(\n",
    "        os.path.join(inbox_dir, fn)\n",
    "        for fn in os.listdir(inbox_dir)\n",
    "        if fn.lower().endswith(\".parquet\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e75cf18-0381-4daa-819d-6ad56e721f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new files in inbox: 2\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "manifest = load_manifest(MANIFEST_PATH)\n",
    "already_processed = {x[\"file\"] for x in manifest.get(\"processed_files\", [])}\n",
    "\n",
    "inbox_files = list_parquet_files(INBOX_DIR)\n",
    "\n",
    "# Ignore the lookup table file \n",
    "candidate_trip_files = [\n",
    "    p for p in inbox_files\n",
    "    if os.path.basename(p) != LOOKUP_TABLE\n",
    "]\n",
    "\n",
    "# Unprocessed files\n",
    "new_trip_files = [\n",
    "    p for p in candidate_trip_files\n",
    "    if os.path.basename(p) not in already_processed\n",
    "]\n",
    "\n",
    "print(f\"Number of new files in inbox: {len(new_trip_files)}\")\n",
    "\n",
    "new_raw_df = None\n",
    "if new_trip_files:\n",
    "    new_raw_df = (\n",
    "        spark.read.parquet(*new_trip_files)\n",
    "        .withColumn(\"source_file\", F.regexp_extract(F.input_file_name(), r\"([^/\\\\\\\\]+)$\", 1))\n",
    "        .withColumn(\"ingested_at\", F.current_timestamp())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a374636-9f7e-46a0-a4ac-bd8925f29d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee', 'cbd_congestion_fee', 'source_file', 'ingested_at']\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      " |-- source_file: string (nullable = false)\n",
      " |-- ingested_at: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_raw_df.columns)\n",
    "new_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024c3124-efc1-48d5-af5a-d4c599894338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zone lookup table\n",
    "\n",
    "LOOKUP_PATH = os.path.join(INBOX_DIR, LOOKUP_TABLE)\n",
    "\n",
    "lookup_df = (\n",
    "    spark.read.parquet(LOOKUP_PATH)\n",
    "    .select(\n",
    "        F.col(\"LocationID\").cast(\"int\").alias(\"LocationID\"),\n",
    "        F.col(\"Borough\").alias(\"Borough\"),\n",
    "        F.col(\"Zone\").alias(\"Zone\"),\n",
    "        F.col(\"service_zone\").alias(\"service_zone\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab19716-fdf0-4f54-8176-71214f1ea0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum transformations\n",
    "\n",
    "def normalize_trip_schema(df):\n",
    "    \"\"\"\n",
    "    Normalizes both Yellow (tpep_*) and Green (lpep_*) taxi schemas to:\n",
    "      pickup_ts, dropoff_ts, pickup_location_id, dropoff_location_id,\n",
    "      passenger_count, trip_distance\n",
    "    \"\"\"\n",
    "    if \"tpep_pickup_datetime\" in df.columns:\n",
    "        pickup_col = \"tpep_pickup_datetime\"\n",
    "        dropoff_col = \"tpep_dropoff_datetime\"\n",
    "    elif \"lpep_pickup_datetime\" in df.columns:\n",
    "        pickup_col = \"lpep_pickup_datetime\"\n",
    "        dropoff_col = \"lpep_dropoff_datetime\"\n",
    "    else:\n",
    "        raise ValueError(\"Could not find pickup/dropoff datetime columns (tpep_* or lpep_*)\")\n",
    "\n",
    "    df = df.withColumnRenamed(pickup_col, \"pickup_ts\").withColumnRenamed(dropoff_col, \"dropoff_ts\")\n",
    "\n",
    "    if \"PULocationID\" in df.columns:\n",
    "        df = df.withColumnRenamed(\"PULocationID\", \"pickup_location_id\")\n",
    "    if \"DOLocationID\" in df.columns:\n",
    "        df = df.withColumnRenamed(\"DOLocationID\", \"dropoff_location_id\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_minimum(raw_df):\n",
    "    \"\"\"\n",
    "    Minimum required transformations:\n",
    "      1) parse/cast types\n",
    "      2) clean invalids/nulls (rules documented below)\n",
    "      3) deduplicate by defined key\n",
    "    \"\"\"\n",
    "    df = normalize_trip_schema(raw_df)\n",
    "\n",
    "    # Cast/parse types\n",
    "    df = (\n",
    "        df\n",
    "        .withColumn(\"pickup_ts\", F.to_timestamp(\"pickup_ts\"))\n",
    "        .withColumn(\"dropoff_ts\", F.to_timestamp(\"dropoff_ts\"))\n",
    "        .withColumn(\"pickup_location_id\", F.col(\"pickup_location_id\").cast(\"int\"))\n",
    "        .withColumn(\"dropoff_location_id\", F.col(\"dropoff_location_id\").cast(\"int\"))\n",
    "        .withColumn(\"passenger_count\", F.col(\"passenger_count\").cast(\"int\"))\n",
    "        .withColumn(\"trip_distance\", F.col(\"trip_distance\").cast(\"double\"))\n",
    "    )\n",
    "\n",
    "    # Cleaning rules\n",
    "    # remove rows with missing timestamps and non-positive duration\n",
    "    df = df.filter(F.col(\"pickup_ts\").isNotNull() & F.col(\"dropoff_ts\").isNotNull())\n",
    "    df = df.filter(F.col(\"dropoff_ts\") > F.col(\"pickup_ts\"))\n",
    "\n",
    "    # remove rows with missing or non-positive location ids\n",
    "    df = df.filter(F.col(\"pickup_location_id\").isNotNull() & (F.col(\"pickup_location_id\") > 0))\n",
    "    df = df.filter(F.col(\"dropoff_location_id\").isNotNull() & (F.col(\"dropoff_location_id\") > 0))\n",
    "\n",
    "    # drop rows with negative number of passengers in the vehicle\n",
    "    df = df.withColumn(\"passenger_count\", F.coalesce(F.col(\"passenger_count\"), F.lit(0)))\n",
    "    df = df.filter(F.col(\"passenger_count\") >= 0)\n",
    "    \n",
    "    # drop rows with trips with missing or non-positive distance\n",
    "    df = df.withColumn(\"trip_distance\", F.coalesce(F.col(\"trip_distance\"), F.lit(0.0)))\n",
    "    df = df.filter(F.col(\"trip_distance\") > 0.0)\n",
    "\n",
    "    # ---- Deduplication ----\n",
    "    dedup_key = [\n",
    "        \"source_file\",\n",
    "        \"pickup_ts\", \"dropoff_ts\",\n",
    "        \"pickup_location_id\", \"dropoff_location_id\",\n",
    "        \"passenger_count\", \"trip_distance\",\n",
    "    ]\n",
    "    df = df.dropDuplicates(dedup_key)\n",
    "\n",
    "    # Derived fields (required later in the pipeline)\n",
    "    df = (\n",
    "        df\n",
    "        .withColumn(\n",
    "            \"trip_duration_minutes\",\n",
    "            (F.col(\"dropoff_ts\").cast(\"long\") - F.col(\"pickup_ts\").cast(\"long\")) / F.lit(60.0)\n",
    "        )\n",
    "        .withColumn(\"pickup_date\", F.to_date(\"pickup_ts\"))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Transform\n",
    "new_clean_df = transform_minimum(new_raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2dcd682-f3c4-402e-a59e-7bc9d6e72d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VendorID', 'pickup_ts', 'dropoff_ts', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'pickup_location_id', 'dropoff_location_id', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee', 'cbd_congestion_fee', 'source_file', 'ingested_at', 'trip_duration_minutes', 'pickup_date']\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- pickup_ts: timestamp (nullable = true)\n",
      " |-- dropoff_ts: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = false)\n",
      " |-- trip_distance: double (nullable = false)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      " |-- source_file: string (nullable = false)\n",
      " |-- ingested_at: timestamp (nullable = false)\n",
      " |-- trip_duration_minutes: double (nullable = true)\n",
      " |-- pickup_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_clean_df.columns)\n",
    "new_clean_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
